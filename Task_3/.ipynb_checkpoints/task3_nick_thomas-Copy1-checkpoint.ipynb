{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 3\n",
    "# Conduct a similar analysis for the returns on (i) a G10 carry trade strategy, (ii) a carry\n",
    "# trade strategy that includes emerging market currencies, (iii) a bond strategy that is\n",
    "# long duration, and (iv) a bond strategy that is long inflation-protected bonds and short\n",
    "# nominal bonds. You are not required to develop these strategies on your own; it is\n",
    "# sufficient if you obtain the returns on indices tracking them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Corinne Vogel\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:7: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n",
      "C:\\Users\\Corinne Vogel\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:7: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n"
     ]
    }
   ],
   "source": [
    "#### Import required Packages ####\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error # to calculate the MSE\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf # To produce ACF plots\n",
    "from statsmodels.graphics.tsaplots import plot_pacf # To produce PACF plots\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose # To decompose Seasons\n",
    "from statsmodels.tsa.stattools import adfuller, kpss # Tests for Stationarity\n",
    "from statsmodels.tsa.ar_model import AutoReg # To produce AR models\n",
    "from statsmodels.stats.anova import anova_lm # To use ANOVA (compare nested models)\n",
    "from statsmodels.tsa.arima.model import ARIMA # To build ARMA & ARIMA Models\n",
    "import statsmodels.stats.diagnostic as dg # To get Breusch-Godfrey Test\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime # to transform variables into datetime objects\n",
    "import math # simple math functions\n",
    "from math import sqrt # square root function\n",
    "import statistics # descriptive statistics library\n",
    "import scipy.stats as stats # descriptive statistics library from scipy\n",
    "import matplotlib.dates as mdates # date formatting\n",
    "from matplotlib.collections import PolyCollection, LineCollection # better plot options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotstyle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn plot style ticks to have nicer looking plots\n",
    "sb.set_style(\"ticks\")\n",
    "sb.mpl.rc(\"figure\", figsize=(16,8))\n",
    "sb.mpl.rc(\"font\", size=14)\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoadData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Date             datetime64[ns]\n",
      "Carry_wEM               float64\n",
      "Carry_G10               float64\n",
      "LongDuration            float64\n",
      "TreasuryBonds           float64\n",
      "Tips                    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# data = data for task 3 (leading economic indicators), data_factors = including factors from task 2, data_strat = strategies as daily indices\n",
    "\n",
    "data = pd.read_excel(\"Cleaned_Data_Task3_nofactors.xlsx\", parse_dates=[\"Date\"])\n",
    "# data_factors = pd.read_excel(\"Cleaned_Data_Task3.xlsx\", parse_dates=[\"Date\"]) # muesch denne eh ihre scheiss auna i euse code haue drum wäred da de cleaned df für das hani aber jetzt nanig benutz\n",
    "data_strat = pd.read_excel(\"Strategy_data.xlsx\", parse_dates=[\"Date\"])\n",
    "\n",
    "# Check\n",
    "print(type(data_strat))\n",
    "print(data_strat.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Carry_wEM  Carry_G10  LongDuration  TreasuryBonds      Tips\n",
      "0 2006-01-02   211.3367   100.4773       408.592       148.0218  186.9924\n",
      "1 2006-01-03   210.0572    99.4694       408.662       148.3258  187.1851\n",
      "2 2006-01-04   210.0472    99.8003       409.295       148.4649  187.2441\n",
      "3 2006-01-05   210.2007    99.3821       409.034       148.4424  186.8009\n",
      "4 2006-01-06   210.3072    99.2073       408.079       148.2647  186.6983\n"
     ]
    }
   ],
   "source": [
    "print(data_strat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cumulative Monthly returns out of Daily Strategy index\n",
    "data_strat.set_index(\"Date\", inplace=True) # bc formula needs datetimeindex\n",
    "\n",
    "strat_mtl = data_strat.pct_change().resample(\"M\").agg(lambda x: ((1+x).prod()-1)*100) # pct_change creates ordinary returns, resample Monthly and aggregating with the (1+x) -1 formula to get monthly ordinary returns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Strategy returns sind jetzt scho in prozent azeigt da will d rf date ja au scho in prozent sind hand denkt das macht sinn\n",
    "2. Hans wieder im Excel \"Strategy_data_commented.xlsx\" checked und es stimmt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF</th>\n",
       "      <th>avg_hours</th>\n",
       "      <th>infexp</th>\n",
       "      <th>initial_claims</th>\n",
       "      <th>YFFR10</th>\n",
       "      <th>building_permits</th>\n",
       "      <th>cons_sent</th>\n",
       "      <th>orders_CG</th>\n",
       "      <th>orders_cap</th>\n",
       "      <th>1_n_portfolio</th>\n",
       "      <th>leading_index</th>\n",
       "      <th>USSLIND</th>\n",
       "      <th>Carry_wEM</th>\n",
       "      <th>Carry_G10</th>\n",
       "      <th>LongDuration</th>\n",
       "      <th>TreasuryBonds</th>\n",
       "      <th>Tips</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-31</th>\n",
       "      <td>0.35</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1622000</td>\n",
       "      <td>0.116000</td>\n",
       "      <td>2212</td>\n",
       "      <td>91.2</td>\n",
       "      <td>167243</td>\n",
       "      <td>58172</td>\n",
       "      <td>0.011327</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.477768</td>\n",
       "      <td>0.599041</td>\n",
       "      <td>-1.248434</td>\n",
       "      <td>-0.257327</td>\n",
       "      <td>-0.009412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-28</th>\n",
       "      <td>0.34</td>\n",
       "      <td>41.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1263000</td>\n",
       "      <td>0.078421</td>\n",
       "      <td>2141</td>\n",
       "      <td>86.7</td>\n",
       "      <td>162922</td>\n",
       "      <td>59887</td>\n",
       "      <td>-0.001383</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.907903</td>\n",
       "      <td>-0.781862</td>\n",
       "      <td>1.221589</td>\n",
       "      <td>0.078366</td>\n",
       "      <td>-0.047974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-31</th>\n",
       "      <td>0.37</td>\n",
       "      <td>41.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1531000</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>2118</td>\n",
       "      <td>88.9</td>\n",
       "      <td>165535</td>\n",
       "      <td>72879</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.58</td>\n",
       "      <td>-2.923076</td>\n",
       "      <td>-3.787657</td>\n",
       "      <td>-4.563440</td>\n",
       "      <td>-0.914071</td>\n",
       "      <td>-2.193861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-04-30</th>\n",
       "      <td>0.36</td>\n",
       "      <td>41.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1761000</td>\n",
       "      <td>0.222632</td>\n",
       "      <td>1998</td>\n",
       "      <td>87.4</td>\n",
       "      <td>165064</td>\n",
       "      <td>60704</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.43</td>\n",
       "      <td>-1.077636</td>\n",
       "      <td>0.306145</td>\n",
       "      <td>-2.827478</td>\n",
       "      <td>-0.339877</td>\n",
       "      <td>-0.084525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-31</th>\n",
       "      <td>0.43</td>\n",
       "      <td>41.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1269000</td>\n",
       "      <td>0.178182</td>\n",
       "      <td>1905</td>\n",
       "      <td>79.1</td>\n",
       "      <td>169705</td>\n",
       "      <td>62738</td>\n",
       "      <td>-0.004814</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.08</td>\n",
       "      <td>-3.675135</td>\n",
       "      <td>-1.507144</td>\n",
       "      <td>0.127257</td>\n",
       "      <td>0.057776</td>\n",
       "      <td>0.294584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-31</th>\n",
       "      <td>0.16</td>\n",
       "      <td>41.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>836000</td>\n",
       "      <td>-0.498636</td>\n",
       "      <td>1485</td>\n",
       "      <td>89.8</td>\n",
       "      <td>198267</td>\n",
       "      <td>64563</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>1.31</td>\n",
       "      <td>1.31</td>\n",
       "      <td>-1.336609</td>\n",
       "      <td>-0.991755</td>\n",
       "      <td>11.012873</td>\n",
       "      <td>3.401541</td>\n",
       "      <td>2.379862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-30</th>\n",
       "      <td>0.18</td>\n",
       "      <td>41.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>940000</td>\n",
       "      <td>-0.353000</td>\n",
       "      <td>1461</td>\n",
       "      <td>93.2</td>\n",
       "      <td>197802</td>\n",
       "      <td>68259</td>\n",
       "      <td>0.008448</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.614866</td>\n",
       "      <td>1.220347</td>\n",
       "      <td>-2.644155</td>\n",
       "      <td>-0.858825</td>\n",
       "      <td>-1.361229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-31</th>\n",
       "      <td>0.16</td>\n",
       "      <td>41.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>766000</td>\n",
       "      <td>-0.123182</td>\n",
       "      <td>1520</td>\n",
       "      <td>95.5</td>\n",
       "      <td>196395</td>\n",
       "      <td>65861</td>\n",
       "      <td>-0.003203</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.41</td>\n",
       "      <td>-1.182872</td>\n",
       "      <td>-0.754390</td>\n",
       "      <td>-1.100045</td>\n",
       "      <td>0.062318</td>\n",
       "      <td>0.255718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30</th>\n",
       "      <td>0.12</td>\n",
       "      <td>41.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>859000</td>\n",
       "      <td>0.259474</td>\n",
       "      <td>1497</td>\n",
       "      <td>96.8</td>\n",
       "      <td>195962</td>\n",
       "      <td>60249</td>\n",
       "      <td>-0.013507</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.125833</td>\n",
       "      <td>1.198699</td>\n",
       "      <td>-0.342397</td>\n",
       "      <td>-0.295745</td>\n",
       "      <td>0.152507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>0.14</td>\n",
       "      <td>41.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1179000</td>\n",
       "      <td>0.311905</td>\n",
       "      <td>1439</td>\n",
       "      <td>99.3</td>\n",
       "      <td>196084</td>\n",
       "      <td>66185</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.847420</td>\n",
       "      <td>-0.052220</td>\n",
       "      <td>-3.117532</td>\n",
       "      <td>-0.559758</td>\n",
       "      <td>0.379122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              RF  avg_hours  infexp  initial_claims    YFFR10  \\\n",
       "Date                                                            \n",
       "2006-01-31  0.35       41.0     3.0         1622000  0.116000   \n",
       "2006-02-28  0.34       41.1     3.0         1263000  0.078421   \n",
       "2006-03-31  0.37       41.1     3.0         1531000  0.130435   \n",
       "2006-04-30  0.36       41.2     3.3         1761000  0.222632   \n",
       "2006-05-31  0.43       41.2     4.0         1269000  0.178182   \n",
       "...          ...        ...     ...             ...       ...   \n",
       "2019-08-31  0.16       41.5     2.7          836000 -0.498636   \n",
       "2019-09-30  0.18       41.5     2.8          940000 -0.353000   \n",
       "2019-10-31  0.16       41.4     2.5          766000 -0.123182   \n",
       "2019-11-30  0.12       41.4     2.5          859000  0.259474   \n",
       "2019-12-31  0.14       41.3     2.3         1179000  0.311905   \n",
       "\n",
       "            building_permits  cons_sent  orders_CG  orders_cap  1_n_portfolio  \\\n",
       "Date                                                                            \n",
       "2006-01-31              2212       91.2     167243       58172       0.011327   \n",
       "2006-02-28              2141       86.7     162922       59887      -0.001383   \n",
       "2006-03-31              2118       88.9     165535       72879       0.007778   \n",
       "2006-04-30              1998       87.4     165064       60704       0.005525   \n",
       "2006-05-31              1905       79.1     169705       62738      -0.004814   \n",
       "...                      ...        ...        ...         ...            ...   \n",
       "2019-08-31              1485       89.8     198267       64563       0.004684   \n",
       "2019-09-30              1461       93.2     197802       68259       0.008448   \n",
       "2019-10-31              1520       95.5     196395       65861      -0.003203   \n",
       "2019-11-30              1497       96.8     195962       60249      -0.013507   \n",
       "2019-12-31              1439       99.3     196084       66185      -0.000097   \n",
       "\n",
       "            leading_index  USSLIND  Carry_wEM  Carry_G10  LongDuration  \\\n",
       "Date                                                                     \n",
       "2006-01-31           1.84     1.84   0.477768   0.599041     -1.248434   \n",
       "2006-02-28           1.62     1.62   0.907903  -0.781862      1.221589   \n",
       "2006-03-31           1.58     1.58  -2.923076  -3.787657     -4.563440   \n",
       "2006-04-30           1.43     1.43  -1.077636   0.306145     -2.827478   \n",
       "2006-05-31           1.08     1.08  -3.675135  -1.507144      0.127257   \n",
       "...                   ...      ...        ...        ...           ...   \n",
       "2019-08-31           1.31     1.31  -1.336609  -0.991755     11.012873   \n",
       "2019-09-30           1.50     1.50   1.614866   1.220347     -2.644155   \n",
       "2019-10-31           1.41     1.41  -1.182872  -0.754390     -1.100045   \n",
       "2019-11-30           1.39     1.39   1.125833   1.198699     -0.342397   \n",
       "2019-12-31           1.52     1.52   0.847420  -0.052220     -3.117532   \n",
       "\n",
       "            TreasuryBonds      Tips  \n",
       "Date                                 \n",
       "2006-01-31      -0.257327 -0.009412  \n",
       "2006-02-28       0.078366 -0.047974  \n",
       "2006-03-31      -0.914071 -2.193861  \n",
       "2006-04-30      -0.339877 -0.084525  \n",
       "2006-05-31       0.057776  0.294584  \n",
       "...                   ...       ...  \n",
       "2019-08-31       3.401541  2.379862  \n",
       "2019-09-30      -0.858825 -1.361229  \n",
       "2019-10-31       0.062318  0.255718  \n",
       "2019-11-30      -0.295745  0.152507  \n",
       "2019-12-31      -0.559758  0.379122  \n",
       "\n",
       "[168 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.set_index(\"Date\", inplace=True) # bc data_strat has datetimeindex it is easier to concat\n",
    "df = pd.concat([data, strat_mtl], axis=1)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instead of logging the big variables we could also rescale them (min-max-rescaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         RF  avg_hours    infexp  initial_claims    YFFR10  building_permits  \\\n",
      "0  0.795455   0.566667  0.371429        0.373147  0.186946          1.000000   \n",
      "1  0.772727   0.600000  0.371429        0.216652  0.178298          0.958211   \n",
      "2  0.840909   0.600000  0.371429        0.333479  0.190267          0.944673   \n",
      "3  0.818182   0.633333  0.457143        0.433740  0.211484          0.874044   \n",
      "4  0.977273   0.633333  0.657143        0.219268  0.201255          0.819305   \n",
      "\n",
      "   cons_sent  orders_CG  orders_cap  1_n_portfolio  leading_index   USSLIND  \\\n",
      "0   0.778742   0.312866    0.391340       0.841510       0.957265  0.957265   \n",
      "1   0.681128   0.251006    0.445075       0.656839       0.910256  0.910256   \n",
      "2   0.728850   0.288414    0.852143       0.789938       0.901709  0.901709   \n",
      "3   0.696312   0.281671    0.470673       0.757207       0.869658  0.869658   \n",
      "4   0.516269   0.348112    0.534403       0.606987       0.794872  0.794872   \n",
      "\n",
      "   Carry_wEM  Carry_G10  LongDuration  TreasuryBonds      Tips  \n",
      "0   0.731142   0.674574      0.428436       0.325819  0.597267  \n",
      "1   0.758370   0.616292      0.517392       0.370744  0.594614  \n",
      "2   0.515864   0.489431      0.309048       0.237928  0.446990  \n",
      "3   0.632683   0.662212      0.371567       0.314771  0.592100  \n",
      "4   0.468258   0.585681      0.477981       0.367989  0.618180  \n"
     ]
    }
   ],
   "source": [
    "# use min-max scaler to rescale the data\n",
    "dff = df\n",
    "\n",
    "# initialize scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# apply scaler\n",
    "dff = pd.DataFrame(scaler.fit_transform(dff), columns = dff.columns)\n",
    "\n",
    "# have a look\n",
    "print(dff.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the big variables\n",
    "#df[\"ln_initial_claims\"] = np.log(df['initial_claims']) \n",
    "#df[\"ln_orders_cap\"] = np.log(df['orders_cap'])\n",
    "#df[\"ln_orders_CG\"] = np.log(df['orders_CG']) \n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RF                  float64\n",
      "avg_hours           float64\n",
      "infexp              float64\n",
      "initial_claims      float64\n",
      "YFFR10              float64\n",
      "building_permits    float64\n",
      "cons_sent           float64\n",
      "orders_CG           float64\n",
      "orders_cap          float64\n",
      "1_n_portfolio       float64\n",
      "leading_index       float64\n",
      "USSLIND             float64\n",
      "Carry_wEM           float64\n",
      "Carry_G10           float64\n",
      "LongDuration        float64\n",
      "TreasuryBonds       float64\n",
      "Tips                float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(type(dff))\n",
    "print(dff.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Carry_G10.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Statistics of the Strategies\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(df.Carry_G10, label=\"Carry G10\", bins=100)\n",
    "#ax.set_xbound(lower=0,upper=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We rescaled the df before, why not rescale the data too? Since we'll use it for our prediction as independant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, strat_mtl, test_size=0.33, random_state=42, shuffle = False)\n",
    "print(\"Test length is:\", len(X_test))\n",
    "print(\"Train length is:\", len(X_train))\n",
    "# at least 30 for regression I think\n",
    "# ich glaube eifach 1-step a head prediction wär imfall au scho gnueg sprich \"all except one\" als trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(122)\n",
    "plt.scatter(X_test.infexp, y_test.Carry_G10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Durbin Watson Test\n",
    "# H0 (null hypothesis): There is no correlation among the residuals.\n",
    "# HA (alternative hypothesis): The residuals are autocorrelated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train.Carry_G10)\n",
    "len(X_train.infexp)\n",
    "X_train.infexp.shape\n",
    "y_train.Carry_G10.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inflation Expectation Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use rule of thumb to calculate number of lags taken into consideration for newey-west HAC and round up\n",
    "print(0.75*len(X_train)**(1/3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G10_Carry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression using Newey West HAC standard errors because of the autocorrelation and heteroscedasticity\n",
    "\n",
    "x = X_train.loc[:,[\"infexp\"]]\n",
    "y = y_train.loc[:, [\"Carry_G10\"]]\n",
    "\n",
    "xt = X_test.loc[:,[\"infexp\"]]\n",
    "yt = y_test.loc[:, [\"Carry_G10\"]]\n",
    "\n",
    "\n",
    "####### I would go with this approach in presence of autocorrelation in the errors ####### \n",
    "model1 = sm.OLS(endog=y, exog=sm.add_constant(x))\n",
    "fit1 = model1.fit(cov_type=\"HAC\",cov_kwds={\"maxlags\":4}) # Newey West SE with 4 lags\n",
    "fit1.summary()\n",
    "## --> Ich hätti so e regression gmacht mit dere cov_type\"HAC\" machsch newey west SE und d lags chasch mit de formle usrechne damits d autocorrelation guet userechnet\n",
    "######################################################################################################\n",
    "\n",
    "# SKLEARN WORKS BUT HAS NO ROBUST STANDARD ERRORS BUILT INTO ITS FIT() FUNCTION\n",
    "model1 = LinearRegression().fit(x, y)\n",
    "yt_pred = model1.predict(xt)\n",
    "resid1 = yt - yt_pred\n",
    "print(\"Durbin Watson test statistics is: \",durbin_watson(resid1), \"must be between 1.5 and 2.5, else autocorrelation present\") # H0: No correlation among residuals -> rejected if test is not between 1.5 and 2.5\n",
    "print(\"The model score in sample is: \", model1.score(x, y, sample_weight=None)) # score uses R^2 and best is 1 and 0 means predicting same value always -> negative is shite\n",
    "print(\"The model score out of sample is: \", model1.score(xt, yt, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carry_wEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn out of sample regression with R^2 as scorer\n",
    "x = X_train.loc[:,[\"infexp\"]]\n",
    "y = y_train.loc[:, [\"Carry_wEM\"]]\n",
    "\n",
    "xt = X_test.loc[:,[\"infexp\"]]\n",
    "yt = y_test.loc[:, [\"Carry_wEM\"]]\n",
    "\n",
    "# SKLEARN WORKS BUT HAS NO ROBUST STANDARD ERRORS BUILT INTO ITS FIT() FUNCTION\n",
    "model2 = LinearRegression().fit(x, y)\n",
    "yt_pred = model2.predict(xt)\n",
    "resid1 = yt - yt_pred\n",
    "print(\"Durbin Watson test statistics is: \",durbin_watson(resid1), \"must be between 1.5 and 2.5, else autocorrelation present\") # H0: No correlation among residuals -> rejected if test is not between 1.5 and 2.5\n",
    "print(\"The model score in sample is: \", model2.score(x, y, sample_weight=None)) # score uses R^2 and best is 1 and 0 means predicting same value always -> negative is shite\n",
    "print(\"The model score out of sample is: \", model2.score(xt, yt, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn out of sample regression with R^2 as scorer\n",
    "x = X_train.loc[:,[\"infexp\"]]\n",
    "y = y_train.loc[:, [\"LongDuration\"]]\n",
    "\n",
    "xt = X_test.loc[:,[\"infexp\"]]\n",
    "yt = y_test.loc[:, [\"LongDuration\"]]\n",
    "\n",
    "# SKLEARN WORKS BUT HAS NO ROBUST STANDARD ERRORS BUILT INTO ITS FIT() FUNCTION\n",
    "model3 = LinearRegression().fit(x, y)\n",
    "yt_pred = model3.predict(xt)\n",
    "resid1 = yt - yt_pred\n",
    "print(\"Durbin Watson test statistics is: \",durbin_watson(resid1), \"must be between 1.5 and 2.5, else autocorrelation present\") # H0: No correlation among residuals -> rejected if test is not between 1.5 and 2.5\n",
    "print(\"The model score in sample is: \", model3.score(x, y, sample_weight=None)) # score uses R^2 and best is 1 and 0 means predicting same value always -> negative is shite\n",
    "print(\"The model score out of sample is: \", model3.score(xt, yt, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treasury Bonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn out of sample regression with R^2 as scorer\n",
    "x = X_train.loc[:,[\"infexp\"]]\n",
    "y = y_train.loc[:, [\"TreasuryBonds\"]]\n",
    "\n",
    "xt = X_test.loc[:,[\"infexp\"]]\n",
    "yt = y_test.loc[:, [\"TreasuryBonds\"]]\n",
    "\n",
    "# SKLEARN WORKS BUT HAS NO ROBUST STANDARD ERRORS BUILT INTO ITS FIT() FUNCTION\n",
    "model4 = LinearRegression().fit(x, y)\n",
    "yt_pred = model4.predict(xt)\n",
    "resid1 = yt - yt_pred\n",
    "print(\"Durbin Watson test statistics is: \",durbin_watson(resid1), \"must be between 1.5 and 2.5, else autocorrelation present\") # H0: No correlation among residuals -> rejected if test is not between 1.5 and 2.5\n",
    "print(\"The model score in sample is: \", model4.score(x, y, sample_weight=None)) # score uses R^2 and best is 1 and 0 means predicting same value always -> negative is shite\n",
    "print(\"The model score out of sample is: \", model4.score(xt, yt, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn out of sample regression with R^2 as scorer\n",
    "x = X_train.loc[:,[\"infexp\"]]\n",
    "y = y_train.loc[:, [\"Tips\"]]\n",
    "\n",
    "xt = X_test.loc[:,[\"infexp\"]]\n",
    "yt = y_test.loc[:, [\"Tips\"]]\n",
    "\n",
    "# SKLEARN WORKS BUT HAS NO ROBUST STANDARD ERRORS BUILT INTO ITS FIT() FUNCTION\n",
    "model5 = LinearRegression().fit(x, y)\n",
    "yt_pred = model5.predict(xt)\n",
    "resid1 = yt - yt_pred\n",
    "print(\"Durbin Watson test statistics is: \",durbin_watson(resid1), \"must be between 1.5 and 2.5, else autocorrelation present\") # H0: No correlation among residuals -> rejected if test is not between 1.5 and 2.5\n",
    "print(\"The model score in sample is: \", model5.score(x, y, sample_weight=None)) # score uses R^2 and best is 1 and 0 means predicting same value always -> negative is shite\n",
    "print(\"The model score out of sample is: \", model5.score(xt, yt, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEI Index as regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G10_Carry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression using Newey West HAC standard errors because of the autocorrelation and heteroscedasticity\n",
    "\n",
    "x = X_train.loc[:,[\"leading_index\"]]\n",
    "y = y_train.loc[:, [\"Carry_G10\"]]\n",
    "\n",
    "xt = X_test.loc[:,[\"leading_index\"]]\n",
    "yt = y_test.loc[:, [\"Carry_G10\"]]\n",
    "\n",
    "\n",
    "####### I would go with this approach in presence of autocorrelation in the errors ####### \n",
    "model6 = sm.OLS(endog=y, exog=sm.add_constant(x))\n",
    "fit1 = model6.fit(cov_type=\"HAC\",cov_kwds={\"maxlags\":4}) # Newey West SE with 4 lags\n",
    "fit1.summary()\n",
    "## --> Ich hätti so e regression gmacht mit dere cov_type\"HAC\" machsch newey west SE und d lags chasch mit de formle usrechne damits d autocorrelation guet userechnet\n",
    "######################################################################################################\n",
    "\n",
    "# SKLEARN WORKS BUT HAS NO ROBUST STANDARD ERRORS BUILT INTO ITS FIT() FUNCTION\n",
    "model6 = LinearRegression().fit(x, y)\n",
    "yt_pred = model6.predict(xt)\n",
    "resid1 = yt - yt_pred\n",
    "print(\"Durbin Watson test statistics is: \",durbin_watson(resid1), \"must be between 1.5 and 2.5, else autocorrelation present\") # H0: No correlation among residuals -> rejected if test is not between 1.5 and 2.5\n",
    "print(\"The model score in sample is: \", model6.score(x, y, sample_weight=None)) # score uses R^2 and best is 1 and 0 means predicting same value always -> negative is shite\n",
    "print(\"The model score out of sample is: \", model6.score(xt, yt, sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockingTimeSeriesSplit():\n",
    "    def __init__(self, n_splits):\n",
    "        self.n_splits = n_splits\n",
    "    \n",
    "    def get_n_splits(self, X, y, groups):\n",
    "        return self.n_splits\n",
    "    \n",
    "    def split(self, X, y=None, groups=None):\n",
    "        n_samples = len(X)\n",
    "        k_fold_size = n_samples // self.n_splits\n",
    "        indices = np.arange(n_samples)\n",
    "\n",
    "        margin = 0\n",
    "        for i in range(self.n_splits):\n",
    "            start = i * k_fold_size\n",
    "            stop = start + k_fold_size\n",
    "            mid = int(0.8 * (stop - start)) + start\n",
    "            yield indices[start: mid], indices[mid + margin: stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btscv = BlockingTimeSeriesSplit(n_splits=5) # ob de shit funktioniert bini mer ned ganz sicher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model1, X_train, y_train, cv=btscv, scoring=\"r2\") # Uses R2 as scorer -> see this docu for different scorers: https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "scores\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Under dem Markdown isch eig nur shit wo bim Code chönt helfe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Help for Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object oriented plotting\n",
    "df1['Date'] = df1['Date'].astype('datetime64[ns]')\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(df1.Date,df1.SARON, label=\"SARON-Fixings\", color=\"grey\")\n",
    "ax.plot(df1.Date,df1.Segmented_regression, label=\"Segmented regression\", color=\"black\",linestyle='dashed')\n",
    "ax.set_xlim([pd.to_datetime('2019-06-13 00:00:00'), pd.to_datetime('2019-12-11 00:00:00')])\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "ax.legend(loc=\"best\")\n",
    "ax.set_ylabel('SARON-Fixings')\n",
    "plt.savefig(\"Graph_exports/ETC1_SegReg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aa336b74a8cbeead930f17f553be49714fc6c4491fbee50d1179d377ec590ae0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
